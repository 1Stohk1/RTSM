# -*- coding: utf-8 -*-
"""ntbk.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10yJO-ZZ7j7C9KWQ5KmOOnSCxO6O4Pvke
"""

from google.colab import drive
drive.mount('/content/drive')

import gdown
!pip install dtaidistance
!pip install tslearn

!gdown 1f4CTEe3Fz0LxncHscL1j2Ma1wn2UAgel

import pandas as pd
import numpy as np

dt_p = pd.read_csv('./P_with_part_program.csv')
p = dt_p[['items','working_time','idle_time','power_avg','power_min','power_max','power_working','power_idle','cycle_time','alarm_1']]
p.to_numpy()

def normalize(data):
  print(f'mean {np.mean(data)}')
  print(f'var {np.var(data)}')
  data = data - np.mean(data)
  data = data / np.sqrt(np.var(data))
  return data


r=1
dataset_x = p.to_numpy()
dataset_x = normalize(dataset_x)

# separate input data from desired_output data: the data is shifted to the left by r positions,
# so that it goes ahead by r temporal steps w.r.t. dataset_x . 
# data_x | 1 | 2 | 3 | 4 | 1 | 2 | 3 | 4 |
#        | <-  <-  <-  <-  <-  <-  <-  <-| 
#    | / | 2 | 3 | 4 | 1 | 2 | 3 | 4 | / |
dataset_y = np.roll(dataset_x,-r,axis=0)

# discard first and last r data-points because they are not meaningfull anymore
dataset_x = dataset_x[r:np.size(dataset_x)-r]
dataset_y = dataset_y[r:np.size(dataset_y)-r]


########### check that data is properly re-arranged ###########
# y[t] = x[t+r]  
# y[t] is r steps in the future w.r.t. x[t]
for t in range(np.size(dataset_x,axis=0)-r):
  assert np.linalg.norm(dataset_x[t+r] - dataset_y[t])==0.0

# separate training data from validation and test.
train_x = dataset_x[:12500].reshape(-1,12500,10)
train_y = dataset_y[:12500,3].reshape(-1,12500,1)

valid_x = dataset_x[12500:20000].reshape(-1,7500,10)
valid_y = dataset_y[12500:20000,3].reshape(-1,7500,1)

test_x = dataset_x[20000:].reshape(-1,5094,10)
test_y = dataset_y[20000:,3].reshape(-1,5094,1)

print(f'\nDATA SHAPES \ntraining data: {np.shape(train_x)},{np.shape(train_y)},\nvalid data: {np.shape(valid_x)},{np.shape(valid_y)}, \ntest data: {np.shape(test_x)}, {np.shape(test_y)}')

from tensorflow import keras

model = keras.Sequential()

model.add(keras.layers.Input(shape=(None,10)))

model.add(keras.layers.LSTM(64,return_sequences=True, kernel_regularizer=keras.regularizers.L1L2(l2=3e-02,))) #

model.add(keras.layers.Dense(1, kernel_regularizer=keras.regularizers.L1L2( l2=1e-01)))

num_train_steps = 300

linear_decay = keras.optimizers.schedules.PolynomialDecay(
      initial_learning_rate=1e-02,
      end_learning_rate=4e-03,
      decay_steps=100,
      power=1)

model.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=linear_decay))
model.summary()

model.fit(train_x, train_y, epochs=num_train_steps,verbose=1, callbacks=[keras.callbacks.TensorBoard(log_dir='./train_logs')])

# when fit is completed, in the terminal:
# tensorboard --logdir=./train_logs
# then follow the link there!

from tslearn.metrics import dtw
out_val = model.predict(valid_x)
out_v = np.array(out_val.reshape(-1), dtype=np.double)
y_v = np.array(valid_y.reshape(-1), dtype=np.double)
dtw_dist = dtw(out_v, y_v, global_constraint="sakoe_chiba", sakoe_chiba_radius=3)

from sklearn.metrics.pairwise import euclidean_distances
eu_dist = euclidean_distances(out_v.reshape(1, -1), y_v.reshape(1, -1))

print("Euclidean Distance           ", eu_dist[0][0])
print("Dynamic Time Warping Distance", dtw_dist)

"""As we can see from above the distance computed with Euclidean Distance is greater compared with the DTW, this can be caused by the fact that the rolling back TS is anticipating part of the power consumption that will happen and because there are nightly periods with few to none interesting informations that can be easily shrinked with DTW."""

from dtaidistance import dtw
from dtaidistance import dtw_visualisation as dtwvis
out_val = model.predict(valid_x)

out_v = np.array(out_val.reshape(-1), dtype=np.double)
y_v = np.array(valid_y.reshape(-1), dtype=np.double)
distance, paths = dtw.warping_paths(out_v, y_v, window=1000, psi=4)
best_path = dtw.best_path(paths)
dtwvis.plot_warpingpaths(out_v, y_v, paths, best_path)

import matplotlib.pyplot as plt
figure, axes = plt.subplots(2, figsize=(36, 4))
axes[0].plot(out_v)
axes[1].plot(y_v)
dtwvis.plot_warping(out_v, y_v, best_path, fig=figure, axs=axes)

"""As we can see from the plot the warping is concerning mainly the idle time, so not really mattering the more interesting working hours."""

def dtw_warnings(out, vals, time, multiplier=0.009):
  # reshape if needed
  out_t =  out.reshape(-1)
  y_t = vals.reshape(-1)

  out_t = np.array(out_t, dtype=np.double)
  y_t = np.array(y_t, dtype=np.double)
  d = dtw.distance_fast(out_t, y_t, use_pruning=True, window=1000, psi=4)

  # compute warnings: warning is triggered if energy consumed in the last 10 minutes was always higher than expected
  l = np.array( list( map( lambda i:  np.all( (y_t[i-time:i] - multiplier*d) > out_t[i-time:i] )*1 ,  list(range(len(out_t)) ) ) ) )
  return l

import plotly.express as px

out_valid = model.predict(valid_x)

l=dtw_warnings(out_valid,valid_y,10)

fig = px.line( )
fig.add_scatter(y=valid_x[0,:,3], name='energy_real')
fig.add_scatter(y=out_valid[0,:,0], name = 'energy_predicted')
fig.add_scatter(y=l, name = 'l')

fig.show()

out_test = model.predict(test_x)

l=dtw_warnings(out_test,test_y,10)

fig = px.line( )
fig.add_scatter(y=test_x[0,:,3], name='energy_real')
fig.add_scatter(y=out_test[0,:,0], name = 'energy_predicted')
fig.add_scatter(y=l, name = 'l')

fig.show()

"""As we can see from the DTW in nearly 2 hours of work we have 4 alarms, in comparison with the multiple alarms founded with the normal measurement"""

len(p)
len(dataset_y)
len(dataset_x)
# separate training data from validation and test.
train_x = dataset_x[:12500]
train_y = dataset_y[:12500,3].reshape(-1,12500,1)

valid_x = dataset_x[12500:20000].reshape(-1,7500,10)
valid_y = dataset_y[12500:20000,3].reshape(-1,7500,1)

test_x = dataset_x[20000:].reshape(-1,5094,10)
test_y = dataset_y[20000:,3].reshape(-1,5094,1)

resh_x = dataset_x[:25094].reshape(-1,25094,10)
resh_y = dataset_y[:25094,3].reshape(-1,25094,1)

out_test = model.predict(resh_x)

l=dtw_warnings(out_test,resh_y, 10, 0.006)

fig = px.line( )
fig.add_scatter(y=resh_x[0,:,3], name='energy_real')
fig.add_scatter(y=out_test[0,:,0], name = 'energy_predicted')
fig.add_scatter(y=l, name = 'l')

fig.show()

dt_p['predicted_alarm'] = np.append(l, 0)

dt_p

model.save('/content/drive/Shareddrives/Materials UNI/UNIPI/Smart App/myModels/model')